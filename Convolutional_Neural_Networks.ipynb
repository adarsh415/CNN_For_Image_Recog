{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnit=input_data.read_data_sets('MNIST_data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnit.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess=tf.InteractiveSession()\n",
    "x=tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
    "y_=tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1=tf.Variable(tf.truncated_normal([5,5,1,32],stddev=0.1))\n",
    "b_conv1=tf.Variable(tf.constant(0.1,shape=[32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "<tf.Variable 'Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (W_conv1)\n",
    "h_conv1=tf.nn.conv2d(x,filter=W_conv1,strides=[1,1,1,1],padding='SAME')\n",
    "h_conv1=tf.nn.relu(h_conv1)\n",
    "h_pool1=tf.nn.max_pool(h_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2=tf.Variable(tf.truncated_normal([5,5,32,64],stddev=0.1))\n",
    "b_conv2=tf.Variable(tf.constant(0.1,shape=[64]))\n",
    "h_conv2=tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)\n",
    "h_pool2=max_pool_2x2(h_conv2)\n",
    "\n",
    "#First full connected Layer\n",
    "W_fc1=tf.Variable(tf.truncated_normal([7*7*64,1024],stddev=0.1))\n",
    "b_fc1=tf.Variable(tf.constant(0.1,shape=[1024]))\n",
    "h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])\n",
    "h_fc1=tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "\n",
    "#Dropout Layer\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#Second Fully Connected Layer\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(.1, shape = [10]))\n",
    "\n",
    "#Final Layer\n",
    "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crossEntropyLoss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainStep = tf.train.AdamOptimizer().minimize(crossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Cross Enropy Loss is illegal; using Cross_Enropy_Loss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Cross Enropy Loss is illegal; using Cross_Enropy_Loss instead.\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar('Cross Enropy Loss', crossEntropyLoss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n",
      "Tensor(\"Reshape_4:0\", shape=(1, 28, 28, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICjCDwT1Xx1e0fnEcIuYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15b07ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = mnit.train.next_batch(1)\n",
    "print (b[0].shape) #b[0] contains the image\n",
    "image = tf.reshape(b[0], [-1,28,28,1])\n",
    "print (image)\n",
    "my_img = image.eval() #here is your image Tensor\n",
    "my_i = my_img.squeeze()\n",
    "plt.imshow(my_i, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.16\n",
      "step 100, training accuracy 0.92\n",
      "step 200, training accuracy 1\n",
      "step 300, training accuracy 0.98\n",
      "step 400, training accuracy 0.94\n",
      "step 500, training accuracy 1\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 1\n",
      "step 900, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "batchSize = 50\n",
    "for i in range(1000):\n",
    "    batch = mnit.train.next_batch(batchSize)\n",
    "    trainingInputs = batch[0].reshape([batchSize,28,28,1])\n",
    "    trainingLabels = batch[1]\n",
    "    if i%10 == 0:\n",
    "        summary = sess.run(merged, {x: trainingInputs, y_: trainingLabels, keep_prob: 1.0})\n",
    "        writer.add_summary(summary, i)\n",
    "    if i%100 == 0:\n",
    "        trainAccuracy = accuracy.eval(session=sess, feed_dict={x:trainingInputs, y_: trainingLabels, keep_prob: 1.0})\n",
    "        print (\"step %d, training accuracy %g\"%(i, trainAccuracy))\n",
    "    trainStep.run(session=sess, feed_dict={x: trainingInputs, y_: trainingLabels, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
